{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Result:  [1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def square(x):\n",
    "    return x*x\n",
    "\n",
    "dataset = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "print ('Dataset: ' + str(dataset))\n",
    "\n",
    "# Run this with a pool of 5 agents having a chunksize of 3 until finished\n",
    "agents = 5\n",
    "chunksize = 3\n",
    "with Pool(processes=agents) as pool:\n",
    "    result = pool.map(square, dataset)\n",
    "\n",
    "\n",
    "# Output the result\n",
    "print ('Result:  ' + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  [1, 16, 81, 2401, 1296, 6561, 625, 4096, 256, 10000, 38416, 20736, 28561, 14641]\n"
     ]
    }
   ],
   "source": [
    "pool=Pool(processes=5)\n",
    "result=[]\n",
    "for mapped_result in pool.imap_unordered(square, dataset):\n",
    "    result.append(mapped_result*mapped_result)\n",
    "\n",
    "print ('Result:  ' + str(result))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Difference of the pool.map and pool.apply:\n",
    "    map takes only one iterable as argument\n",
    "   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  {1: [1], 2: [4], 3: [9], 4: [16], 5: [25], 6: [36], 7: [49], 8: [64], 9: [81], 10: [100], 11: [121], 12: [144], 13: [169], 14: [196]}\n"
     ]
    }
   ],
   "source": [
    "result= {data: pool.map(square, [data]) for data in dataset}\n",
    "print ('Result:  ' + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are actually are doing several mapping, each with a single element list  (?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  {1: [1], 2: [4], 3: [9], 4: [16], 5: [25], 6: [36], 7: [49], 8: [64], 9: [81], 10: [100], 11: [121], 12: [144], 13: [169], 14: [196]}\n"
     ]
    }
   ],
   "source": [
    "result= {data: pool.map(square, [data]) for data in dataset}\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "\n",
    "print ('Result:  ' + str(result))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What join and close do anyway?\n",
    "\n",
    "Pool.close() is typically called when the parallelizable part of the main program is finished. \n",
    "Then the worker processes will terminate when all work already assigned has completed.\n",
    "\n",
    "It's also excellent practice to call Pool.join() to wait for the worker processes to terminate. \n",
    "Among other reasons, there's often no good way to report exceptions in parallelized code and Pool.join() provides a synchronization point that can report some exceptions that occurred in worker processes that you'd otherwise never see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pool not running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0f98e4f389a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, args, kwds, callback, error_callback)\u001b[0m\n\u001b[1;32m    360\u001b[0m         '''\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pool not running\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mApplyResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_taskqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Pool not running"
     ]
    }
   ],
   "source": [
    "result = pool.apply_async(square, [10])    \n",
    "print (result.get(timeout=1) )\n",
    "print (pool.map(square, range(10))  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "pool=Pool(processes=5)\n",
    "result = pool.apply_async(square, [10])    \n",
    "print (result.get(timeout=1) )\n",
    "print (pool.map(square, range(10))  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apply_async method can be used for (different) processes that can be run in parallel yet may take different amount of time.\n",
    "and then resume next steps when all are done.\n",
    "\n",
    "something like this:\n",
    "\n",
    "pool = Pool(processes=3)\n",
    "parsed = pool.apply_async(Process1, [largefile])\n",
    "pattern = pool.apply_async(Process2, [bigfile])\n",
    "calc_res = pool.apply_async(Process3, [integer])\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "final = FinalProcess(parsed.get(), pattern.get(), calc_res.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is that apply_async needs a get() method to call the results but map does not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool=Pool(processes=5)\n",
    "result = pool.apply(square, range(10))    \n",
    "print (result.get(timeout=1) )\n",
    "print (pool.map(square, range(10))  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here in above you cannot give a single list (iterable) as input, like we do in map, so the above syntax is wrong!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool=Pool(processes=5)\n",
    "result =[ pool.apply(square, args=[arg1]) for arg1 in range(10) ]\n",
    "# which is the same as:\n",
    "result2= pool.map(square, range(10)) \n",
    "print (result.get(timeout=1) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "pool=Pool(processes=5)\n",
    "result =[ pool.apply(square, [arg1]) for arg1 in range(10) ]\n",
    "\n",
    "# which is the same as:\n",
    "result2= pool.map(square, range(10)) \n",
    "print (result)\n",
    "print (result2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument of apply also must be a list, although looks like we can't give all inputs at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
      "[0, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-118:\n",
      "Process ForkPoolWorker-117:\n",
      "Process ForkPoolWorker-119:\n",
      "Process ForkPoolWorker-116:\n",
      "Process ForkPoolWorker-120:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'howmany_within_range2' on <module '__main__'>\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'howmany_within_range2' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'howmany_within_range2' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'howmany_within_range2' on <module '__main__'>\n",
      "AttributeError: Can't get attribute 'howmany_within_range2' on <module '__main__'>\n"
     ]
    }
   ],
   "source": [
    "def custom_multiply(x,y):\n",
    "    return x*y*y\n",
    "\n",
    "def unpack_multiply(args):\n",
    "    return custom_multiply(args[0],args[1])\n",
    "\n",
    "pool=Pool(processes=5)\n",
    "result =[ pool.apply(custom_multiply, (arg1,10) ) for arg1 in range(10) ]\n",
    "\n",
    "# which is the same as:\n",
    "result2= pool.map(unpack_multiply, [ (item,10) for item in range(10)] ) \n",
    "\n",
    "print (result)\n",
    "print (result2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting note around previous note is that when we entered a single argument as (arg), it considered it as integer and not tuple, so we needed []. but here we donot need to enter [] and () gives the tuple.\n",
    "\n",
    "Also, for multiple arguments, even if use the unpacking function like above, I ran into some issues becasue \n",
    "the object given as input was not passed correctly.\n",
    "(Now was this an issue with my unpacking code?)\n",
    "\n",
    "The other method that can be used to solve this is starmap. effectively, Pool.starmap() is like a version of Pool.map() that accepts arguments.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n"
     ]
    }
   ],
   "source": [
    "result= pool.starmap(custom_multiply, [ (item,10) for item in range(10)] ) \n",
    "print (result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issues of the pool with codes that are not self contained.\n",
    "\n",
    "Looks like the pool should not include any method that cannot be solved by itself.\n",
    "So in that sense, all the read and writes should be removed from the method.\n",
    "Also if you try to use this pool function in a method of a class\n",
    "then should introduce some separate class or method to run it with pool\n",
    "I am not sure at this point if one can solve any non-static methods of a class using the pool.\n",
    "The info here may be usefull also https://gist.github.com/bnyeggen/1086393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.RandomState(100)\n",
    "arr = np.random.randint(0, 10, size=[200000, 5])\n",
    "data = arr.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the apply_async with a callback function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " if  don’t provide a callback, then you get a list of pool.ApplyResult objects\n",
    " which contains the computed output values from each process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3), (1, 2), (2, 3), (3, 1), (4, 3), (5, 2), (6, 1), (7, 4), (8, 2), (9, 2), (10, 3), (12, 4), (13, 4), (11, 1), (15, 0), (17, 3), (14, 2), (16, 4), (18, 2), (19, 2)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "\n",
    "def howmany_within_range2(i, row, minimum, maximum):\n",
    "    \"\"\"Returns how many numbers lie within `maximum` and `minimum` in a given `row`\"\"\"\n",
    "    count = 0\n",
    "    for n in row:\n",
    "        if minimum <= n <= maximum:\n",
    "            count = count + 1\n",
    "    return (i, count)\n",
    "\n",
    "def collect_result(result):\n",
    "    global results\n",
    "    results.append(result)\n",
    "\n",
    "for i, row in enumerate(data):\n",
    "    pool.apply_async(howmany_within_range2, args=(i, row, 4, 8), callback=collect_result)\n",
    "\n",
    "\n",
    "# results.sort(key=lambda x: x[0])\n",
    "results_final = [r for i, r in results]\n",
    "\n",
    "print(results[:20])\n",
    "# print(results_final[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 1, 3, 2, 1, 4, 2, 2, 3, 1, 4, 4, 2, 0, 4, 3, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "result_objects = [pool.apply_async(howmany_within_range2, args=(i, row, 4, 8)) for i, row in enumerate(data)]\n",
    "\n",
    "# result_objects is a list of pool.ApplyResult objects\n",
    "results = [r.get()[1] for r in result_objects]\n",
    "print(results[:20])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering worker  3\n",
      "Entering worker  0\n",
      "Entering worker  1Entering worker \n",
      " 2\n",
      "Exiting worker\n",
      "Entering worker  4\n",
      "Exiting worker\n",
      "Entering worker  5\n",
      "Exiting worker\n",
      "Entering worker Exiting worker \n",
      "6\n",
      "Entering worker  7\n",
      "worker_response\n",
      "worker_response\n",
      "worker_response\n",
      "worker_response\n",
      "Exiting worker\n",
      "Exiting worker\n",
      "Exiting worker\n",
      "Exiting worker\n",
      "worker_response\n",
      "worker_response\n",
      "worker_response\n",
      "worker_response\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "\n",
    "def callback(a):\n",
    "    print (a)\n",
    "\n",
    "\n",
    "def worker(i, n):\n",
    "    print ('Entering worker ', i)\n",
    "    sleep(n)\n",
    "    print ('Exiting worker')\n",
    "    return 'worker_response'\n",
    "\n",
    "\n",
    "pool = Pool(4)\n",
    "a = [pool.apply_async(worker, (i, 4), callback=callback) for i in range(8)]\n",
    "for i in a:\n",
    "    i.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/48807196/difference-between-apply-and-apply-async-in-python-multiprocessing-module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additiona readings\n",
    "\n",
    "\n",
    "https://stackabuse.com/parallel-processing-in-python/\n",
    "\n",
    "https://docs.python.org/2/library/multiprocessing.html#using-a-pool-of-workers\n",
    "\n",
    "\n",
    "https://docs.python.org/2/library/multiprocessing.html\n",
    "https://docs.python.org/3/library/multiprocessing.html\n",
    "\n",
    "\n",
    "https://helpful.knobs-dials.com/index.php/Python_usage_notes/Multiprocessing_notes\n",
    "\n",
    "\n",
    "https://www.binpress.com/simple-python-parallelism/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit5a164f0abf4544fc96ad5349ac07c616"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
