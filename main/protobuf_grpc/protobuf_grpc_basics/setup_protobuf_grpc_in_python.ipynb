{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"setup_protobuf_grpc_in_python.ipynb","provenance":[],"collapsed_sections":["6usdMPwBsT0Z","_fb7MB_X4f2h"],"authorship_tag":"ABX9TyMVBN86S5oeW8djKsJcMLcp"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Y25AP20HrEul"},"source":["## Distinguish protobuf and grpc\n"]},{"cell_type":"markdown","metadata":{"id":"QphwJQLwrPND"},"source":["so a question that seemed both confusing and silly to me what is the difference of these two, particularly when I was trying to setup the compilers and install them in my environment. well, the quick short answer is that grpc is utilizing the protobuf and add server/client features (HTTP, tcp, ect.). \n","\n","So it seems the setup of grpc library for python would be sufficient and will include protobuf compiler as well (verify). \n"," But lets say we wanted to use the protobuf by itself, how the api would work?\n","\n","\n",">Protocol Buffers (a.k.a., protobuf) are Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data. You can find protobuf's documentation on the Google Developers site.\n","\n",">The initial purpose of Protocol Buffers was to simplify the work with request/response protocols. Before ProtoBuf, Google used a different format which required additional handling of marshaling for the messages sent.\n","\n",">>marshaling is the process of transforming the memory representation of an object to a data format suitable for storage or transmission,[citation needed] and it is typically used when data must be moved between different parts of a computer program or from one program to another. Marshalling is similar to serialization and is used to communicate to remote objects with an object, in this case a serialized object. It simplifies complex communication, using composite objects in order to communicate instead of primitives. \n","\n",">ProtoBuf allows changes to the protocol to be introduced without breaking compatibility. Also, servers can pass around the data and execute read operations on the data without modifying its content.\n","\n",">Since the format is somewhat self-describing, ProtoBuf is used as a base for automatic code generation for Serializers and Deserializers.\n","\n",">Another interesting use case is how Google uses it for short-lived Remote Procedure Calls (RPC) and to persistently store data in Bigtable. Due to their specific use case, they integrated RPC interfaces into ProtoBuf. This allows for quick and straightforward code stub generation that can be used as starting points for the actual implementation. (More on ProtoBuf RPC.)\n","\n","\n","\n","\n",">gRPC uses protocol buffers for defining the type of data (also called Interface Definition Language (IDL)) to be sent between the gRPC client and the gRPC server. It also uses it as the message interchange format.\n"]},{"cell_type":"markdown","metadata":{"id":"ibuFBGLMt_Gr"},"source":["So it seems that the short final verdict is that the protobuf ( alone by itself) is for  writing/reading data (to a file) in a manner that is language free. (e.g. you write in Go, read in python, etc.), but when it comes to RPC (Remote Procedure Call, or sending receiving data between clients and servers) it mostly is the domain of the gRPC.  \n","I found a bunch of tutorials, e.g. [this](https://www.freecodecamp.org/news/googles-protocol-buffers-in-python/) is good to understand protobuffs better.\n","\n","Also:\n","\n","https://medium.com/@EmperorRXF/evaluating-performance-of-rest-vs-grpc-1b8bdf0b22da\n","\n","https://www.semantics3.com/blog/a-simplified-guide-to-grpc-in-python-6c4e25f0c506/\n","\n","https://www.datadoghq.com/blog/engineering/protobuf-parsing-in-python/\n","\n","https://dev.to/chen/exploring-google-protobuffers-with-python-1gmd\n","\n","https://pythonhosted.org/protobuf3/index.html\n","\n","\n","pretty much beating around the same bush.\n","\n","good tutorials on this so far:\n","\n","https://www.datascienceblog.net/post/programming/essential-protobuf-guide-python/\n","\n","https://gist.github.com/doi-t/2b8b2d773930018d27192c312df7c779\n","\n","\n","\n","That being said, the Protobuf itself allows for some functionalities in the RPC.\n","\n",">Defining Services\n","If you want to use your message types with an RPC (Remote Procedure Call) system, you can define an RPC service interface in a .proto file and the protocol buffer compiler will generate service interface code and stubs in your chosen language. So, for example, if you want to define an RPC service with a method that takes your SearchRequest and returns a SearchResponse, you can define it in your .proto file as follows:\n","\n","```\n","service SearchService {\n","  rpc Search(SearchRequest) returns (SearchResponse);\n","}\n","\n","```\n","\n",">By default, the protocol compiler will then generate an abstract interface called SearchService and a corresponding \"stub\" implementation. The stub forwards all calls to an RpcChannel, which in turn is an abstract interface that you must define yourself in terms of your own RPC system. For example, you might implement an RpcChannel which serializes the message and sends it to a server via HTTP. In other words, the generated stub provides a type-safe interface for making protocol-buffer-based RPC calls, without locking you into any particular RPC implementation. \n","\n","more on this is [here](https://developers.google.com/protocol-buffers/docs/proto)\n","and I could not find much more.\n","\n","my take on it is that the protobuf can provide the means to fcailitate, if someone has a custom RPC service.\n","\n","BTW, this [page](https://www.freecodecamp.org/news/author/timgrossmann/) is a cool! Nonprofit that helps teach coding for free!\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6usdMPwBsT0Z"},"source":["## setting up the grpc/protobuf compilers for python"]},{"cell_type":"markdown","metadata":{"id":"3E4HkMsWsmti"},"source":["okay seems there are so many different ways to do this !\n","when first I got into this topic, I went to the google page for installing the protobuf compiler, and it was a rather needlessly complicated and confusing process.\n","\n","I think I should have wrote on some NB about this, in the [docker tutorial repo](https://github.com/sakha002/docker-tutorials/tree/master/main/protobuf/protobuf)\n","\n","so it seems in general there are at least 4 different ways to do this:\n","\n","* the long manual way (that I went in that dockerfile)\n","* just using the pip install protobuf\n","* using the pip install grpc\n","* using some other version of protobuf compiler which gives a more readable python class output. pip install [betterproto](https://github.com/danielgtaylor/python-betterproto)\n","\n","\n","( I want to go through the second and forth options again, but will pass this for now)\n","\n","\n","\n","So lets say we have the compiler and libraries set up. what is next?\n","1.   write down our proto messages, etc. and create the .proto file. \n","2.   compile it and create the python (go, etc.) data classes that would be used in the python code.\n","3. develop server and client codes that generate/ populate  or consume the .proto data on each side.  (for example in the client code, when the data in placed inside these python classes the proto message is populated and sent to the server, but this seems to be part of the grpc tech, what happens if we only have protobuf?, we still have two apps in each side of the proto data?!)\n","\n","I will put a place holder for all these tree steps to dig more. The first and second items though, have looked at before and the thrid one is the focus for now\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JyHPeKO8uJtp"},"source":["okay seems like the second approach, by itself will not be sufficient. It is the second step of installing protobuf for python:\n","```\n","apt install -y protobuf-compiler\n","pip3 install protobuf\n","```\n","\n","but still the first line would replace, download and set up of protobuf binaries.\n","more on this is [here](https://github.com/protocolbuffers/protobuf/tree/master/python)\n","\n","\n","okay then the other question that I had here, is that what is this \n","\n","pip install protobuf-compiler\n","\n","which is described [here](https://pypi.org/project/protobuf-compiler/)\n","? probably another way for setting up the protobuf!?!\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_gA_vv9B4aCf"},"source":["## how to develop .proto data mode?"]},{"cell_type":"markdown","metadata":{"id":"lF6BlOpb46EK"},"source":["okay so writing the .proto seems a bit complicated first, but it is really not that hard. In a nutshell, just need to assign an integer index for each item of the message ( starting from either 0 or 1) and then identifying the type of each atribute, field, etc.  well, TBC."]},{"cell_type":"markdown","metadata":{"id":"_fb7MB_X4f2h"},"source":["## how to compile the .proto data model (and use it?)\n"]},{"cell_type":"markdown","metadata":{"id":"XuQFlH1P5mbC"},"source":["I have already gone through several examples on compling the proto file, actually as part of setting up the complier, but more on this will come here soon!.\n"]},{"cell_type":"markdown","metadata":{"id":"-Fcw64yp58pl"},"source":["#### how to effectively  utilize the proto data model inside python (or how to convert it to json, etc.)"]},{"cell_type":"markdown","metadata":{"id":"Ty1t0ytO6MWq"},"source":["well this is actually an important topic that I need to go through, lets say we created the python classes, are they really the same as a normal python class? how can we modify and/or manipulatre it? can we combine  or inherit from other classes? does it  depend on the compiler we used?  well TBC\n"]},{"cell_type":"markdown","metadata":{"id":"I1AcTvk94tom"},"source":["## how to setup client and server in protobuf/grpc?"]},{"cell_type":"markdown","metadata":{"id":"-H855O957GtQ"},"source":["well, this seems to be somehow part of how to use the protobufs, but it is more focused on how the two sides of the API would comunicate, what are the pieaces that should be in place, how it works, etc. \n","again, is it specific to grpc or include protobud as well?\n"]},{"cell_type":"markdown","metadata":{"id":"b9RzBZvp75gB"},"source":["#### lets again start with the simple example:"]},{"cell_type":"markdown","metadata":{"id":"bA8Yklgg8EMp"},"source":["okay so let's start with a simple protobuf example.\n","\n","so the most of work again was on how to set up the protobuf compiler, etc on the docker, (included in example directory)\n","\n","\n"," but the proto message is pretty simple:\n","\n","```\n","enum TaskState {\n","    TASK_OPEN = 0;\n","    TASK_IN_PROGRESS = 1;\n","    TASK_POST_PONED = 2;\n","    TASK_CLOSED = 3;\n","    TASK_DONE = 4;\n","}\n","\n","message TodoList {\n","    int32 owner_id = 1;\n","    string owner_name = 2;\n","\n","    message ListItems {\n","        TaskState state = 1;\n","        string task = 2;\n","        string due_date = 3;\n","    }\n","\n","    repeated ListItems todos = 3;\n","}\n","\n","```\n","\n","and the usage of the protobuf message is even more simple / obsured:\n","\n","```\n","import todolist_pb2 as TodoList\n","\n","my_list = TodoList.TodoList()\n","my_list.owner_id = 1234\n","my_list.owner_name = \"Tim\"\n","\n","first_item = my_list.todos.add()\n","first_item.state = TodoList.TaskState.Value(\"TASK_DONE\")\n","first_item.task = \"Test ProtoBuf for Python\"\n","first_item.due_date = \"31.10.2019\"\n","\n","print(my_list)\n","```\n","\n","well still is okay for a first one. now I am interested for a better example, preferably one that has a client and a server.\n"]},{"cell_type":"markdown","metadata":{"id":"WnRB7-NB0Kc1"},"source":["#### Second Example\n","\n"]},{"cell_type":"markdown","metadata":{"id":"y8-y6BVt0Qqe"},"source":["The second example I saw on protobuf was the one provided by google and that one bsaically provided a code that was defining (entering) contacts into an addressbook, storing the addressbook on file, and then another code that would read the file and print the list of contacts in output.\n","\n","The part that I was interested on this code was that it seemed to me that it could be possible to have both codes running and interacting with the data file at the same time"]},{"cell_type":"markdown","metadata":{"id":"jSKUBkjVIliG"},"source":["#### grpc Example\n"]},{"cell_type":"markdown","metadata":{"id":"zsP9zZx4IrtS"},"source":["from https://github.com/grpc/grpc/blob/v1.34.0/examples/protos/helloworld.proto\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EuLOXYE0LZpU"},"source":["The proto file is like this:\n","\n","```\n","syntax = \"proto3\";\n","\n","option java_multiple_files = true;\n","option java_package = \"io.grpc.examples.helloworld\";\n","option java_outer_classname = \"HelloWorldProto\";\n","option objc_class_prefix = \"HLW\";\n","\n","package helloworld;\n","\n","// The greeting service definition.\n","service Greeter {\n","  // Sends a greeting\n","  rpc SayHello (HelloRequest) returns (HelloReply) {}\n","}\n","\n","// The request message containing the user's name.\n","message HelloRequest {\n","  string name = 1;\n","}\n","\n","// The response message containing the greetings\n","message HelloReply {\n","  string message = 1;\n","}\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"Kl9mQHPhMh6C"},"source":["so looks like the grpc compilation would add an additional python file helloworld_pb2_grpc.py\n","to cover the aspects related to service, etc.\n","\n","```\n","# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!\n","import grpc\n","\n","import helloworld_pb2 as helloworld__pb2\n","\n","\n","class GreeterStub(object):\n","  \"\"\"The greeting service definition.\n","  \"\"\"\n","\n","  def __init__(self, channel):\n","    \"\"\"Constructor.\n","    Args:\n","      channel: A grpc.Channel.\n","    \"\"\"\n","    self.SayHello = channel.unary_unary(\n","        '/helloworld.Greeter/SayHello',\n","        request_serializer=helloworld__pb2.HelloRequest.SerializeToString,\n","        response_deserializer=helloworld__pb2.HelloReply.FromString,\n","        )\n","\n","\n","class GreeterServicer(object):\n","  \"\"\"The greeting service definition.\n","  \"\"\"\n","\n","  def SayHello(self, request, context):\n","    \"\"\"Sends a greeting\n","    \"\"\"\n","    context.set_code(grpc.StatusCode.UNIMPLEMENTED)\n","    context.set_details('Method not implemented!')\n","    raise NotImplementedError('Method not implemented!')\n","\n","\n","def add_GreeterServicer_to_server(servicer, server):\n","  rpc_method_handlers = {\n","      'SayHello': grpc.unary_unary_rpc_method_handler(\n","          servicer.SayHello,\n","          request_deserializer=helloworld__pb2.HelloRequest.FromString,\n","          response_serializer=helloworld__pb2.HelloReply.SerializeToString,\n","      ),\n","  }\n","  generic_handler = grpc.method_handlers_generic_handler(\n","      'helloworld.Greeter', rpc_method_handlers)\n","  server.add_generic_rpc_handlers((generic_handler,))\n","```"]},{"cell_type":"markdown","metadata":{"id":"tZnh4k2BPF0m"},"source":["server:\n","\n","```\n","\n","\"\"\"The Python implementation of the GRPC helloworld.Greeter server.\"\"\"\n","\n","from concurrent import futures\n","import logging\n","\n","import grpc\n","\n","import helloworld_pb2\n","import helloworld_pb2_grpc\n","\n","\n","class Greeter(helloworld_pb2_grpc.GreeterServicer):\n","\n","    def SayHello(self, request, context):\n","        return helloworld_pb2.HelloReply(message='Hello, %s!' % request.name)\n","\n","\n","def serve():\n","    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))\n","    helloworld_pb2_grpc.add_GreeterServicer_to_server(Greeter(), server)\n","    server.add_insecure_port('[::]:50051')\n","    server.start()\n","    server.wait_for_termination()\n","\n","\n","if __name__ == '__main__':\n","    logging.basicConfig()\n","    serve()\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"bbauWuzeQ-UG"},"source":[]},{"cell_type":"markdown","metadata":{"id":"nWvv2CWHQqj2"},"source":["the client:\n","\n","\n","```\n","\"\"\"The Python implementation of the GRPC helloworld.Greeter client.\"\"\"\n","\n","from __future__ import print_function\n","import logging\n","\n","import grpc\n","\n","import helloworld_pb2\n","import helloworld_pb2_grpc\n","\n","\n","def run():\n","    # NOTE(gRPC Python Team): .close() is possible on a channel and should be\n","    # used in circumstances in which the with statement does not fit the needs\n","    # of the code.\n","    with grpc.insecure_channel('localhost:50051') as channel:\n","        stub = helloworld_pb2_grpc.GreeterStub(channel)\n","        response = stub.SayHello(helloworld_pb2.HelloRequest(name='you'))\n","    print(\"Greeter client received: \" + response.message)\n","\n","\n","if __name__ == '__main__':\n","    logging.basicConfig()\n","    run()\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Q0OboBEDWmxx"},"source":["so this example seems simple enough. Note sure if it help to set up the docker for it.\n","\n","\n","There are a bunch of questions that poped up thinking about this example.\n","\n","\n","Is it possible to change the defenition of python class at some point in the server when the class is established from the messages?! \n","Well I need to add some features to this data structure.\n","looking at the defenitions and auto-generated classes, made me realzie it is not good idea to make any changes.\n","\n","So what should I do for this purpose?\n"]},{"cell_type":"markdown","metadata":{"id":"-aa4HdnTX1ED"},"source":["#### How to add features to the python classes (generated from proto?)"]},{"cell_type":"markdown","metadata":{"id":"1TIGLZd_X-Jy"},"source":["well looks like this example is close to my problem:\n","\n","https://stackoverflow.com/questions/55048021/subclassing-a-message-to-add-additional-behavior"]},{"cell_type":"markdown","metadata":{"id":"52AUxQq_YR8p"},"source":["So the problem was defined like this:\n","\n","\n","```\n","import data_pb2 as pb2\n","\n","class Status(pb2.Status):\n","    def __init__(self, streamer, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.streamer = streamer\n","\n","    def __setattr__(self, key, value):\n","        super().__setattr__(key, value)\n","        self.streamer.send_update()\n","```\n","\n","which obviously gives error.\n","\n","\n","Protocol Buffers and O-O Design Protocol buffer classes are basically dumb data holders (like structs in C); they don't make good first class citizens in an object model. If you want to add richer behaviour to a generated class, the best way to do this is **to wrap the generated protocol buffer class in an application-specific class**. Wrapping protocol buffers is also a good idea if you don't have control over the design of the .proto file (if, say, you're reusing one from another project). In that case, **you can use the wrapper class to craft an interface better suited to the unique environment of your application**: hiding some data and methods, exposing convenience functions, etc. **You should never add behaviour to the generated classes by inheriting from them**. This will break internal mechanisms and is not good object-oriented practice anyway."]},{"cell_type":"markdown","metadata":{"id":"J3yLuDvFY9sQ"},"source":["So the solutin was offered like this:\n","\n","```\n","class Status:\n","    def __init__(self, *args, **kwargs):\n","        self.status = pb2.Status(*args, **kwargs)\n","        self.event = None\n","\n","    def __setattr__(self, key, value):\n","        if key == 'status' or key == 'event':\n","            super().__setattr__(key, value)\n","        else:\n","            super().__getattribute__('status').__setattr__(key, value)\n","            super().__getattribute__('event').set()\n","\n","    def __getattr__(self, item):\n","        if item == 'event' or item == 'status':\n","            return super().__getattribute__(item)\n","        else:\n","            return super().__getattribute__('status').__getattribute__(item)\n","\n","\n","event = threading.Event()\n","status = Status(version=\"1\",\n","                )\n","status_streamer = StatusStreamer(status, event)\n","status.event = event\n","status.version = str(int(status.version) + 1) #this triggers set to be called inside setattr, which results in the threads in SatusStreamer to stream the update\n","```\n","\n","well I don't understand this. hmmm.\n","\n"]},{"cell_type":"code","metadata":{"id":"DSxsnDV0YPy7"},"source":[],"execution_count":null,"outputs":[]}]}